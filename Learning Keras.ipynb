{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from Citra import Citra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopLearning(Callback):\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        super(Callback, self).__init__()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        loss, acc = self.model.evaluate(self.X, self.Y, verbose = 0)\n",
    "#         print('Akurasi : ' + str(acc * 100) + '\\n')\n",
    "        \n",
    "        if acc > 0.99:\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "        if acc >= 0.92:\n",
    "            self.model.save('hasil learning/Model NN ' + str(acc * 100) + '.h5')\n",
    "#             print(\"Saved model to disk\\n\")\n",
    "            \n",
    "def getTrainingData(path, label, limit):\n",
    "    trainImages = []\n",
    "    \n",
    "    c = 1\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.png') == False:\n",
    "            continue\n",
    "            \n",
    "        filePath = os.path.join(path, file)\n",
    "        img = Citra(cv.imread(filePath))\n",
    "        img.resize((128, 128))\n",
    "        trainImages.append([img.getHistogram(), label])\n",
    "        \n",
    "        if c == limit:\n",
    "            break\n",
    "            \n",
    "        c += 1\n",
    "        \n",
    "    return numpy.array(trainImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = getTrainingData('data/Dataset/v2/1', [1 ,0, 0, 0], 80)\n",
    "k2 = getTrainingData('data/Dataset/v2/2', [0, 1, 0, 0], 80)\n",
    "k3 = getTrainingData('data/Dataset/v2/3', [0, 0, 1, 0], 80)\n",
    "k4 = getTrainingData('data/Dataset/v2/4', [0, 0, 0, 1], 80)\n",
    "training_images = numpy.concatenate((k1, k2, k3, k4), axis = 0)\n",
    "training_data = numpy.array([i[0] for i in training_images])\n",
    "training_label = numpy.array([i[1] for i in training_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. define the network\n",
    "model = Sequential()\n",
    "model.add(Dense(500, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(250, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "# 2. compile the network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "# 3. fit the network\n",
    "history = model.fit(training_data, training_label, epochs = 1500, batch_size = 30, verbose = 2, callbacks = [StopLearning(training_data, training_label)])\n",
    "# 4. evaluate the network\n",
    "loss, accuracy = model.evaluate(training_data, training_label)\n",
    "print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "# 5. make predictions\n",
    "probabilities = model.predict(training_data)\n",
    "# print(probabilities)\n",
    "predictions = numpy.argmax(probabilities, axis=1)\n",
    "# print(predictions)\n",
    "accuracy = numpy.mean(predictions == numpy.argmax(training_label, axis=1))\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 600)               461400    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 450)               270450    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 250)               112750    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4)                 1004      \n",
      "=================================================================\n",
      "Total params: 845,604\n",
      "Trainable params: 845,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "320/320 [==============================] - 0s 93us/step\n",
      "Akurasi :93.125\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('hasil learning/Model NN 94.375.h5')\n",
    "loaded_model.compile(loss = 'categorical_crossentropy', optimizer= 'sgd', metrics=['accuracy'])\n",
    "fit = loaded_model.fit(x = training_data, y = training_label, epochs = 3000, batch_size = 30, verbose = 0, callbacks = [StopLearning(training_data, training_label)])\n",
    "        \n",
    "loaded_model.summary()\n",
    "loss, accuracy = loaded_model.evaluate(training_data, training_label)\n",
    "print('Akurasi :' + str(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testing_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ce923c2e1160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mindeks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'mentah'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'setah'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'setang'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'matang'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCitra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testing_data' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (20, 40))\n",
    "indeks = ['mentah', 'setah', 'setang', 'matang']\n",
    "\n",
    "for counter, data in enumerate(testing_data):\n",
    "    y = fig.add_subplot(20, 12, counter + 1)\n",
    "    img = Citra(testing_data[counter])\n",
    "    histogram = img.getHistogram()\n",
    "    output = model.predict(numpy.array([histogram]))\n",
    "    \n",
    "    y.imshow(cv.cvtColor(testing_data[counter], cv.COLOR_BGR2RGB))\n",
    "    plt.title(indeks[numpy.argmax(output)])\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
